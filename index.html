<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>SPCC Practicals (Python/C Examples)</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/tailwindcss/2.2.19/tailwind.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/highlight.min.js"></script>
    <!-- Load Python and C language support for highlight.js -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/languages/python.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/languages/c.min.js"></script>
     <!-- Using Arduino theme -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/styles/arduino-light.min.css">
    <style>
        body { font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; }
        .code-block-container {
            position: relative; /* Needed for absolute positioning of button */
            margin-bottom: 1.5em;
        }
        pre {
            padding: 1em;
            padding-top: 2.5em; /* Add padding to top to avoid overlap with button */
            border-radius: 0.5em;
            overflow-x: auto;
            font-size: 0.9em;
            border: 1px solid #e1e4e8;
        }
        code.hljs {
           background: none;
        }
        .code-container {
            background-color: #ffffff;
            padding: 1.5rem 2rem;
            border-radius: 0.75rem;
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.08);
            margin-bottom: 2.5rem;
            border: 1px solid #d1d5db;
        }
        h2 {
            margin-bottom: 1rem;
            color: #1e40af;
            border-bottom: 2px solid #93c5fd;
            padding-bottom: 0.5rem;
            font-weight: 600;
         }
        h3 { margin-bottom: 0.75rem; color: #1f2937; font-weight: 500; }
        p { margin-bottom: 1rem; color: #4b5563; line-height: 1.6; }
        .run-command {
            background-color: #eef2ff; border-left: 4px solid #6366f1; color: #3730a3;
            padding: 1rem; margin-bottom: 1rem; border-radius: 0.25rem; font-size: 0.875rem;
            line-height: 1.5;
        }
        .run-command code {
            background-color: #e0e7ff; padding: 0.1em 0.4em; border-radius: 0.25rem;
            font-family: 'Courier New', Courier, monospace; color: #312e81; font-weight: 500;
        }
         .run-command strong { color: #4338ca; }

         /* Copy Button Styles */
         .copy-btn {
            position: absolute;
            top: 0.5rem;
            right: 0.5rem;
            background-color: #6b7280; /* Gray-500 */
            color: white;
            border: none;
            padding: 0.3rem 0.6rem;
            border-radius: 0.375rem; /* rounded-md */
            font-size: 0.75rem; /* text-xs */
            cursor: pointer;
            transition: background-color 0.2s ease-in-out;
            opacity: 0.7; /* Slightly transparent */
         }
         .copy-btn:hover {
            background-color: #4b5563; /* Gray-600 */
            opacity: 1;
         }
         .copy-btn.copied {
             background-color: #10b981; /* Emerald-500 */
         }
    </style>
</head>
<body class="bg-gray-50">
    <header class="bg-gradient-to-r from-blue-700 to-indigo-800 text-white p-6 shadow-lg sticky top-0 z-10">
        <div class="container mx-auto text-center">
            <h1 class="text-3xl font-bold">SPCC Python/C Examples</h1>
        </div>
    </header>

    <main class="container mx-auto py-10 px-4">

        <!-- ==========================
             TWO-PASS ASSEMBLER
             ========================== -->
        <div class="code-container">
            <h2 class="text-2xl">1. Two-Pass Assembler</h2>

            <!-- Pass 1: Symbol/Literal Table -->
            <div>
                <h3 class="text-xl">1a. Pass 1: Generate Symbol Table & Literal Table</h3>
                <p>Simulates assembler Pass 1 to build the Symbol Table (symbols and their addresses) and Literal Table (literals encountered and their assigned addresses, often allocated during LTORG or END).</p>
                 <div class="run-command">
                    <strong>Language:</strong> Python<br>
                    <strong>Execution:</strong> <code>python assembler_pass1_sym_lit.py</code> (Save code as this file)
                </div>
                 <div class="code-block-container">
                     <button class="copy-btn" data-target-id="code-assembler-1a">Copy</button>
                    <pre id="code-assembler-1a"><code class="language-python">
import pandas as pd

def is_opcode(mnemonic):
    """Checks if a mnemonic is a known opcode (simplified MOT)."""
    mot = {
        'STOP': 'IS,00', 'ADD': 'IS,01', 'SUB': 'IS,02', 'MULT': 'IS,03',
        'MOVER': 'IS,04', 'MOVEM': 'IS,05', 'COMP': 'IS,06', 'BC': 'IS,07',
        'DIV': 'IS,08', 'READ': 'IS,09', 'PRINT': 'IS,10'
    }
    return mnemonic in mot

def is_directive(directive):
    """Checks if a mnemonic is an assembler directive (simplified POT)."""
    pot = {'START': 'AD,01', 'END': 'AD,02', 'ORIGIN': 'AD,03',
           'EQU': 'AD,04', 'LTORG': 'AD,05', 'DS': 'DL,01', 'DC': 'DL,02'}
    return directive in pot

def pass1(source_code):
    """Simulates Pass 1 of a simple assembler."""
    symbol_table = {}
    literal_table = {}
    literal_pool = [] # Stores literals encountered before LTORG/END
    location_counter = 0
    lit_tab_index = 1 # Index for literal table entries
    pool_tab_index = 0 # Index for the current literal pool

    print("--- Pass 1 Processing ---")
    print(f"{'LC':<8}{'Label':<10}{'Opcode':<10}{'Operand':<15}{'Comment'}")
    print("-" * 50)

    for line in source_code:
        parts = line.split(maxsplit=3) # Split into max 4 parts (label, opcode, operand, comment)
        label, opcode, operand, comment = "", "", "", ""
        current_lc = location_counter

        # Basic parsing (assumes simple structure)
        idx = 0
        # Check for label (if first part isn't opcode/directive)
        if len(parts) > 0 and not is_opcode(parts[idx]) and not is_directive(parts[idx]):
            label = parts[idx]
            idx += 1

        if len(parts) > idx:
            opcode = parts[idx]
            idx += 1
        if len(parts) > idx:
            operand = parts[idx]
            idx += 1
        if len(parts) > idx:
            comment = parts[idx] # The rest is comment

        print(f"{current_lc:<8}{label:<10}{opcode:<10}{operand:<15}{comment}")

        # Handle START directive
        if opcode == 'START':
            if operand:
                location_counter = int(operand)
            continue # Don't increment LC for START itself

        # Handle Label
        if label:
            if label in symbol_table:
                print(f"Error: Duplicate symbol '{label}' at LC {current_lc}")
            else:
                symbol_table[label] = {'address': current_lc, 'defined': True} # Mark as defined

        # Handle Literals
        if operand and operand.startswith("='"):
            if operand not in literal_table: # Add only if new unique literal
                # Check if already in the current pool to avoid duplicates in pool
                is_in_pool = any(item['literal'] == operand for item in literal_pool if item['pool'] == pool_tab_index)
                if not is_in_pool:
                    literal_pool.append({'id': lit_tab_index, 'literal': operand, 'address': None, 'pool': pool_tab_index})
                    literal_table[operand] = {'id': lit_tab_index, 'address': None} # Add to main table too
                    lit_tab_index += 1

        # Handle LTORG or END (Process Literal Pool)
        if opcode == 'LTORG' or opcode == 'END':
            print(f"   -> Processing Literal Pool #{pool_tab_index}")
            for entry in literal_pool:
                # Assign address only if not already assigned and belongs to current pool
                if entry['address'] is None and entry['pool'] == pool_tab_index:
                    print(f"{location_counter:<8}{'*':<10}{entry['literal']:<10}")
                    entry['address'] = location_counter
                    literal_table[entry['literal']]['address'] = location_counter # Update main table
                    location_counter += 1 # Assume each literal takes 1 unit
            if opcode == 'LTORG':
                 pool_tab_index += 1 # Move to the next pool index
            if opcode == 'END':
                break # Stop processing

        # Update Location Counter (Simplified)
        if is_opcode(opcode):
            location_counter += 1 # Assume 1 word per instruction
        elif opcode == 'DS': # Define Storage
            if operand:
                location_counter += int(operand)
        elif opcode == 'DC': # Define Constant
            location_counter += 1 # Assume 1 word

        # ORIGIN and EQU need special handling (more complex)

    print("-" * 50)
    return symbol_table, literal_table, literal_pool # Return final pool too for inspection

# --- Example Usage ---
source_code = [
    "START 200",
    "READ A",
    "READ B",
    "MOVER AREG, ='1'", # Literal 1
    "MOVER BREG, ='2'", # Literal 2
    "ADD AREG, B",
    "LOOP MOVER CREG, A",
    "ADD CREG, ='1'",   # Literal 1 again
    "MOVEM CREG, D",
    "LTORG",            # Process literals ='1', ='2'
    "NEXT SUB AREG, ='3'", # Literal 3
    "BC LT, LOOP",      # Branch instruction
    "STOP",
    "A DS 1",
    "B DS 1",
    "C DS 1",
    "D DS 1",
    "END"
]

symbol_table, literal_table_final, _ = pass1(source_code)

print("\n--- Final Symbol Table ---")
print(f"{'Symbol':<10}{'Address':<10}")
print("-" * 20)
df_sym = pd.DataFrame.from_dict(symbol_table, orient='index')
print(df_sym[['address']]) # Displaying only address for simplicity

print("\n--- Final Literal Table ---")
print(f"{'ID':<5}{'Literal':<10}{'Address':<10}")
print("-" * 25)
# Sort by ID for clarity
sorted_lits = sorted(literal_table_final.items(), key=lambda item: item[1]['id'])
for lit, data in sorted_lits:
     print(f"{data['id']:<5}{lit:<10}{data['address'] if data['address'] is not None else 'N/A':<10}")

</code></pre>
                 </div>
            </div>

             <!-- Pass 1: Base Table / LC -->
            <div>
                <h3 class="text-xl">1b. Pass 1: Generate Base Table & Location Counter (LC)</h3>
                <p>Focuses on calculating the Location Counter (LC) during Pass 1. Base Table generation depends heavily on specific directives like `USING`, which is simplified here.</p>
                <div class="run-command">
                    <strong>Language:</strong> Python<br>
                    <strong>Execution:</strong> <code>python assembler_pass1_lc_base.py</code> (Save code as this file)
                </div>
                <div class="code-block-container">
                     <button class="copy-btn" data-target-id="code-assembler-1b">Copy</button>
                    <pre id="code-assembler-1b"><code class="language-python">
import pandas as pd

def is_opcode(mnemonic): # Same as before
    mot = {'STOP':'IS,00', 'ADD':'IS,01', 'SUB':'IS,02', 'MULT':'IS,03', 'MOVER':'IS,04', 'MOVEM':'IS,05', 'COMP':'IS,06', 'BC':'IS,07', 'DIV':'IS,08', 'READ':'IS,09', 'PRINT':'IS,10'}
    return mnemonic in mot

def is_directive(directive): # Same as before
    pot = {'START':'AD,01', 'END':'AD,02', 'ORIGIN':'AD,03', 'EQU':'AD,04', 'LTORG':'AD,05', 'DS':'DL,01', 'DC':'DL,02', 'USING':'AD,06'} # Added USING
    return directive in pot

def calculate_lc_and_base(source_code):
    location_counter = 0
    base_table = {} # Stores register availability for base addressing {register: address}
    lc_history = [] # Track LC for each line

    print("--- Pass 1 LC Calculation & Base Table Simulation ---")
    print(f"{'LC':<8}{'Line':<40}")
    print("-" * 50)

    for line_num, line in enumerate(source_code):
        parts = line.split(maxsplit=3)
        label, opcode, operand, comment = "", "", "", ""
        current_lc = location_counter

        # Basic parsing
        idx = 0
        if len(parts) > 0 and not is_opcode(parts[idx]) and not is_directive(parts[idx]):
            idx += 1 # Skip label for LC calculation focus

        if len(parts) > idx: opcode = parts[idx]; idx += 1
        if len(parts) > idx: operand = parts[idx]; idx += 1

        lc_history.append(current_lc) # Store LC *before* processing the line
        print(f"{current_lc:<8}{line}")

        # Update LC based on opcode/directive
        if opcode == 'START':
            if operand: location_counter = int(operand)
            continue
        elif opcode == 'END':
            # Process any pending literals (simplified)
            # In a real assembler, literal pool processing happens here too
            break # Stop processing
        elif opcode == 'LTORG':
            # Process literal pool (simplified - assume 1 word per literal)
            # location_counter += calculate_literal_pool_size() # Placeholder
            print("   -> LTORG encountered (LC increment would depend on literal pool size)")
            pass # Simplified: No direct LC change for LTORG itself here
        elif opcode == 'USING':
             # Example: USING *, 15  (Use current address, register 15)
             # Example: USING BASE, R2
             # This directive doesn't change LC but updates the base table
             if operand:
                 parts_op = operand.split(',')
                 if len(parts_op) == 2:
                     base_val_str = parts_op[0].strip()
                     reg_str = parts_op[1].strip()
                     # In a real assembler, base_val_str needs evaluation (*) or symbol lookup
                     base_address = current_lc if base_val_str == '*' else -1 # Placeholder for symbol lookup
                     base_table[reg_str] = base_address
                     print(f"   -> Base Table Update: Register {reg_str} set to base address {base_address}")
                 else:
                     print(f"   -> Warning: Invalid USING operand format: {operand}")

        elif opcode == 'DS':
            if operand: location_counter += int(operand)
        elif opcode == 'DC':
             location_counter += 1 # Assume 1 word
        elif is_opcode(opcode):
             location_counter += 1 # Assume 1 word per instruction
        # ORIGIN, EQU would require more complex LC handling

    print("-" * 50)

    print("\n--- Location Counter History ---")
    for i, lc in enumerate(lc_history):
        print(f"Line {i+1}: {source_code[i]:<30} LC = {lc}")

    print("\n--- Final Base Table (Simulated) ---")
    if not base_table:
        print("Base Table is empty.")
    else:
        print(f"{'Register':<10}{'Base Address':<15}")
        print("-" * 25)
        df_base = pd.DataFrame.from_dict(base_table, orient='index', columns=['Base Address'])
        print(df_base)

    return lc_history, base_table

# --- Example Usage ---
source_code_lc = [
    "PG1 START 100",
    "    USING *, 15",   # Use current LC (100) as base for R15
    "    READ A",
    "L1  MOVER AREG, B",
    "    USING L1, 14",  # Use address of L1 as base for R14
    "    ADD AREG, C",
    "    BC ANY, L1",
    "A   DS 1",
    "B   DS 1",
    "C   EQU A+1",      # EQU doesn't increment LC
    "    END"
]

lc_history, base_table = calculate_lc_and_base(source_code_lc)

</code></pre>
                </div>
            </div>

             <!-- Display MOT/POT -->
            <div>
                <h3 class="text-xl">1c. Display MOT & POT Contents</h3>
                <p>Shows predefined Machine Opcode Table (MOT) and Pseudo Opcode Table (POT) used by the assembler.</p>
                 <div class="run-command">
                    <strong>Language:</strong> Python<br>
                    <strong>Libraries:</strong> Pandas (for display)<br>
                    <strong>Install:</strong> <code>pip install pandas</code><br>
                    <strong>Execution:</strong> <code>python assembler_mot_pot.py</code> (Save code as this file)
                </div>
                <div class="code-block-container">
                    <button class="copy-btn" data-target-id="code-assembler-1c">Copy</button>
                    <pre id="code-assembler-1c"><code class="language-python">
import pandas as pd

# Machine Opcode Table (MOT) - Mnemonic -> (Opcode Type, Machine Code, Length)
# Types: IS (Imperative Statement), DL (Declarative), AD (Assembler Directive)
# Machine Code and Length are simplified placeholders here.
mot = {
    # Imperative Statements (IS)
    'STOP':  {'type': 'IS', 'code': '00', 'length': 1},
    'ADD':   {'type': 'IS', 'code': '01', 'length': 1},
    'SUB':   {'type': 'IS', 'code': '02', 'length': 1},
    'MULT':  {'type': 'IS', 'code': '03', 'length': 1},
    'MOVER': {'type': 'IS', 'code': '04', 'length': 1},
    'MOVEM': {'type': 'IS', 'code': '05', 'length': 1},
    'COMP':  {'type': 'IS', 'code': '06', 'length': 1},
    'BC':    {'type': 'IS', 'code': '07', 'length': 1},
    'DIV':   {'type': 'IS', 'code': '08', 'length': 1},
    'READ':  {'type': 'IS', 'code': '09', 'length': 1},
    'PRINT': {'type': 'IS', 'code': '10', 'length': 1},
}

# Pseudo Opcode Table (POT) / Assembler Directives Table
# Mnemonic -> (Type, Routine/Code)
pot = {
    # Assembler Directives (AD)
    'START':  {'type': 'AD', 'code': '01'},
    'END':    {'type': 'AD', 'code': '02'},
    'ORIGIN': {'type': 'AD', 'code': '03'},
    'EQU':    {'type': 'AD', 'code': '04'},
    'LTORG':  {'type': 'AD', 'code': '05'},
    'USING':  {'type': 'AD', 'code': '06'}, # Added USING
    # Declaration Statements (DL)
    'DS':     {'type': 'DL', 'code': '01'},
    'DC':     {'type': 'DL', 'code': '02'},
}

# --- Display Tables ---
print("--- Machine Opcode Table (MOT) ---")
df_mot = pd.DataFrame.from_dict(mot, orient='index')
print(df_mot)

print("\n--- Pseudo Opcode Table (POT) / Directives ---")
df_pot = pd.DataFrame.from_dict(pot, orient='index')
print(df_pot)

</code></pre>
                 </div>
            </div>
        </div>

        <!-- ==========================
             SINGLE-PASS MACRO PROCESSOR
             ========================== -->
        <div class="code-container">
            <h2 class="text-2xl">2. Single-Pass Macro Processor</h2>

            <!-- Display MNT, MDT, ALA -->
            <div>
                <h3 class="text-xl">2a. Display MNT, MDT, ALA</h3>
                <p>Processes macro definitions to build and display the Macro Name Table (MNT), Macro Definition Table (MDT), and Argument List Array (ALA) structure (simulated).</p>
                 <div class="run-command">
                    <strong>Language:</strong> Python<br>
                     <strong>Libraries:</strong> Pandas (for display)<br>
                    <strong>Install:</strong> <code>pip install pandas</code><br>
                    <strong>Execution:</strong> <code>python macro_pass1_tables.py</code> (Save code as this file)
                </div>
                 <div class="code-block-container">
                    <button class="copy-btn" data-target-id="code-macro-2a">Copy</button>
                    <pre id="code-macro-2a"><code class="language-python">
import pandas as pd

def build_macro_tables(source_code):
    mnt = {}  # Macro Name Table: {name: {'num_args': k, 'mdt_index': p}}
    mdt = []  # Macro Definition Table: stores lines of macro definition
    ala_structure = {} # Simulates ALA: {macro_name: {formal_arg: '#index'}}

    in_macro_definition = False
    current_macro_name = None
    arg_index = 0

    print("--- Macro Processing (Building Tables) ---")
    for line_num, line in enumerate(source_code):
        line = line.strip()
        parts = line.split(maxsplit=2) # Split carefully: [label/name] [MACRO/opcode] [args/operand]
        directive_or_name = parts[0] if parts else ""
        args_part = parts[1] if len(parts) > 1 else ""

        print(f"Line {line_num+1}: {line}")

        if directive_or_name == 'MACRO':
            if in_macro_definition:
                print("Error: Nested MACRO definitions not supported.")
                continue
            if len(parts) < 1: # Only MACRO directive is needed on this line
                 print("Info: Found MACRO directive.")
                 in_macro_definition = True
                 # Expect prototype on the next line
                 continue
            else:
                 print("Warning: Expected only 'MACRO' directive on this line.")
                 in_macro_definition = True # Still try to proceed
                 continue

        elif directive_or_name == 'MEND':
            if not in_macro_definition:
                print("Error: MEND found outside of macro definition.")
                continue
            print(f"   -> Ended Macro Definition: {current_macro_name}")
            mdt.append(line) # Add MEND line
            in_macro_definition = False
            current_macro_name = None
            continue

        elif in_macro_definition:
             # Check if this is the prototype line (immediately after MACRO)
             if current_macro_name is None:
                 header_parts = line.split(maxsplit=1)
                 current_macro_name = header_parts[0]
                 if current_macro_name in mnt: # Check for redefinition
                      print(f"Error: Macro '{current_macro_name}' redefined.")
                      in_macro_definition = False # Abort this definition
                      continue
                 mdt.append(line) # Store prototype in MDT
                 mdt_start_index = len(mdt) - 1 # Index where this macro starts in MDT

                 formal_args = []
                 if len(header_parts) > 1:
                     # Split arguments, handling commas and spaces, remove '&'
                     formal_args = [arg.strip().lstrip('&') for arg in header_parts[1].split(',') if arg.strip()]

                 mnt[current_macro_name] = {'num_args': len(formal_args), 'mdt_index': mdt_start_index}

                 # Build ALA structure for this macro
                 ala_structure[current_macro_name] = {}
                 for i, arg in enumerate(formal_args):
                      ala_structure[current_macro_name][arg] = f"#{i+1}" # Map formal arg to positional index #1, #2...

                 print(f"   -> Started Macro Definition: {current_macro_name} with args {formal_args}")
             else:
                 # This is a line inside the macro body
                 processed_line = line
                 # Replace formal parameters with positional markers in MDT line
                 if current_macro_name in ala_structure:
                      for formal_arg, positional_marker in ala_structure[current_macro_name].items():
                          # Use word boundaries to avoid partial replacements (basic regex)
                          # Need to import re for this
                          import re
                          processed_line = re.sub(r'\b&' + re.escape(formal_arg) + r'\b', positional_marker, processed_line)
                 mdt.append(processed_line)

        # Outside macro definition - could be regular assembly code or macro call
        # (Not processed further in this example focused on table building)

    print("-" * 40)
    return mnt, mdt, ala_structure

# --- Example Usage ---
macro_source = [
    "MACRO",
    "INCR &MEM, ®, &CONST", # Prototype
    " MOVER ®, &MEM",
    " ADD ®, &CONST",
    " MOVEM ®, &MEM",
    "MEND",
    "",
    "MACRO",
    "DECR &ARG1",          # Macro with one argument
    " SUB AREG, &ARG1",
    "MEND",
    "",
    "START 100",
    " INCR A, AREG, ='1'", # Macro Call (not expanded here)
    " DECR B",            # Macro Call (not expanded here)
    "END"
]

mnt, mdt, ala = build_macro_tables(macro_source)

print("\n--- Macro Name Table (MNT) ---")
# Use pandas for nice printing
df_mnt = pd.DataFrame.from_dict(mnt, orient='index')
if not df_mnt.empty:
    print(df_mnt)
else:
    print("(empty)")


print("\n--- Macro Definition Table (MDT) ---")
print(f"{'Index':<6}{'Definition Line'}")
print("-" * 40)
for i, line in enumerate(mdt):
    print(f"{i:<6}{line}")

print("\n--- Argument List Array (ALA) Structure (Simulated) ---")
if not ala:
    print("(empty)")
else:
    for name, mapping in ala.items():
        print(f" Macro '{name}':")
        if not mapping:
            print("    (No arguments)")
        else:
            for formal, positional in mapping.items():
                print(f"    &{formal} -> {positional}")

</code></pre>
                 </div>
            </div>

            <!-- Expansion with Predefined Tables -->
            <div>
                 <h3 class="text-xl">2b. Display Macro Expansion (Predefined Tables)</h3>
                <p>Simulates macro expansion using predefined MNT and MDT. Focuses on substituting arguments during expansion.</p>
                 <div class="run-command">
                    <strong>Language:</strong> Python<br>
                    <strong>Execution:</strong> <code>python macro_pass1_expand_predefined.py</code> (Save code as this file)
                </div>
                <div class="code-block-container">
                     <button class="copy-btn" data-target-id="code-macro-2b">Copy</button>
                    <pre id="code-macro-2b"><code class="language-python">
# --- Predefined Tables (Example) ---
# Usually built by a previous pass or definition phase
predefined_mnt = {
    # Name: {#Params, MDT_Start_Index}
    'INCR': {'num_args': 3, 'mdt_index': 0},
    'DECR': {'num_args': 1, 'mdt_index': 5} # Corrected index for DECR
}

predefined_mdt = [
    # Index 0 - INCR Prototype
    "INCR &MEM, ®, &CONST",
    # Index 1 - INCR Body
    " MOVER #2, #1",   # Positional args: #1=MEM, #2=REG, #3=CONST
    # Index 2 - INCR Body
    " ADD #2, #3",
    # Index 3 - INCR Body
    " MOVEM #2, #1",
    # Index 4 - MEND for INCR
    "MEND",
    # Index 5 - DECR Prototype
    "DECR &ARG1",
    # Index 6 - DECR Body
    " SUB AREG, #1", # Positional arg: #1=ARG1
    # Index 7 - MEND for DECR
    "MEND"
]

def expand_macro(macro_call_line, mnt, mdt):
    """Expands a single macro call line."""
    parts = macro_call_line.split(maxsplit=1)
    macro_name = parts[0]
    actual_args_str = parts[1] if len(parts) > 1 else ""

    if macro_name not in mnt:
        return [f"; Error: Macro '{macro_name}' not found."] # Return error as comment

    macro_info = mnt[macro_name]
    mdt_start_index = macro_info['mdt_index']
    num_expected_args = macro_info['num_args']

    # Create Actual Argument List (ALA) for this specific call
    actual_args = [arg.strip() for arg in actual_args_str.split(',') if arg.strip()] if actual_args_str else []

    if len(actual_args) != num_expected_args:
        return [f"; Error: Macro '{macro_name}' expects {num_expected_args} args, got {len(actual_args)}."]

    # Build the ALA mapping for this call: #1 -> actual_arg1, #2 -> actual_arg2, ...
    call_ala = {f"#{i+1}": actual_args[i] for i in range(len(actual_args))}

    print(f"   -> Expanding '{macro_name}' with ALA: {call_ala}")

    expanded_code = []
    # Start reading MDT from the line *after* the prototype
    mdt_current_index = mdt_start_index + 1
    while mdt_current_index < len(mdt):
        mdt_line = mdt[mdt_current_index].strip()
        if mdt_line == 'MEND':
            break # Stop expansion for this macro

        # Substitute positional parameters with actual arguments
        expanded_line = mdt_line
        for positional, actual in call_ala.items():
             # Be careful with simple replace - might replace substrings unintentionally
             # Using split/join or regex might be safer in complex cases
             expanded_line = expanded_line.replace(positional, actual)

        expanded_code.append("    " + expanded_line) # Indent expanded code
        mdt_current_index += 1

    return expanded_code


# --- Example Usage ---
source_code_to_expand = [
    "START 100",
    " INCR A, AREG, ='1'", # Macro Call 1
    " L1 MOVER BREG, C",   # Regular instruction
    " DECR B",            # Macro Call 2
    " INCR D, CREG, X",   # Macro Call 3
    " STOP",
    "A DS 1",
    "B DS 1",
    "C DS 1",
    "D DS 1",
    "X DC '5'",
    " END"
]

print("--- Macro Expansion Simulation (using predefined tables) ---")
output_code = []
macros_found = predefined_mnt.keys()

for line in source_code_to_expand:
    line_strip = line.strip()
    if not line_strip: # Skip empty lines
        output_code.append(line)
        continue

    parts = line_strip.split(maxsplit=1)
    potential_macro_name = parts[0]

    if potential_macro_name in macros_found:
        print(f"\nProcessing Macro Call: {line_strip}")
        # Need to pass the full line including args to expand_macro
        expansion = expand_macro(line_strip, predefined_mnt, predefined_mdt)
        output_code.extend(expansion) # Add expanded lines
        print(f"   -> Expansion:")
        for expanded_line in expansion:
            print(expanded_line)
    else:
        # Not a macro call, copy the line as is
        output_code.append(line)

print("\n--- Final Output Code (with Expansion) ---")
for line in output_code:
    print(line)

</code></pre>
                </div>
            </div>

            <!-- Identify and Expand -->
            <div>
                <h3 class="text-xl">2c. Identify Macros and Perform Expansion</h3>
                <p>Combines definition processing and expansion in a single pass (conceptual). It builds tables as definitions are found and expands calls encountered later.</p>
                 <div class="run-command">
                    <strong>Language:</strong> Python<br>
                     <strong>Libraries:</strong> Pandas (for display)<br>
                    <strong>Install:</strong> <code>pip install pandas</code><br>
                    <strong>Execution:</strong> <code>python macro_pass1_identify_expand.py</code> (Save code as this file)
                </div>
                 <div class="code-block-container">
                    <button class="copy-btn" data-target-id="code-macro-2c">Copy</button>
                    <pre id="code-macro-2c"><code class="language-python">
import pandas as pd
import re # Import regex

mnt = {}  # Macro Name Table: {name: {'num_args': k, 'mdt_index': p}}
mdt = []  # Macro Definition Table: stores lines of macro definition with positional args
output_code = [] # Final expanded code
ala_definition_structure = {} # Stores formal to positional mapping during definition

in_macro_definition = False
current_macro_name = None

def process_source(source_code):
    global mnt, mdt, output_code, ala_definition_structure, in_macro_definition, current_macro_name

    print("--- Single Pass Macro Processing (Define & Expand) ---")

    line_iter = iter(enumerate(source_code)) # Use iterator to potentially skip lines

    while True:
        try:
            line_num, line = next(line_iter)
            line_strip = line.strip()

            if not line_strip: # Skip empty lines
                if not in_macro_definition: output_code.append(line)
                continue

            parts = line_strip.split(maxsplit=1) # Split only once for name/rest
            potential_macro_name = parts[0]
            rest_of_line = parts[1] if len(parts) > 1 else ""

            # --- Handling Definition ---
            if potential_macro_name == 'MACRO' and not in_macro_definition:
                in_macro_definition = True
                print(f"Line {line_num+1}: Found MACRO directive.")
                # Get the next line, which MUST be the prototype
                try:
                    proto_line_num, proto_line = next(line_iter)
                    proto_line_strip = proto_line.strip()
                    proto_parts = proto_line_strip.split(maxsplit=1)
                    current_macro_name = proto_parts[0]

                    if not current_macro_name or current_macro_name == 'MACRO' or current_macro_name == 'MEND':
                         print(f"Error Line {proto_line_num+1}: Invalid macro name '{current_macro_name}'. Skipping definition.")
                         # Skip until MEND potentially
                         while True:
                             nl_num, nl = next(line_iter)
                             if nl.strip() == 'MEND': break
                         in_macro_definition = False
                         current_macro_name = None
                         continue

                    if current_macro_name in mnt:
                         print(f"Error Line {proto_line_num+1}: Macro '{current_macro_name}' redefined. Skipping definition.")
                         # Skip until MEND potentially
                         while True:
                             nl_num, nl = next(line_iter)
                             if nl.strip() == 'MEND': break
                         in_macro_definition = False
                         current_macro_name = None
                         continue

                    print(f"Line {proto_line_num+1}: Defining Macro '{current_macro_name}'")
                    mdt.append(proto_line_strip) # Store prototype itself
                    mdt_start_index = len(mdt) - 1

                    formal_args_str = proto_parts[1] if len(proto_parts) > 1 else ""
                    formal_args = [arg.strip().lstrip('&') for arg in formal_args_str.split(',') if arg.strip()]

                    mnt[current_macro_name] = {'num_args': len(formal_args), 'mdt_index': mdt_start_index}
                    ala_definition_structure[current_macro_name] = {formal: f"#{i+1}" for i, formal in enumerate(formal_args)}

                except StopIteration:
                    print(f"Error Line {line_num+1}: MACRO defined but no prototype or MEND found.")
                    in_macro_definition = False
                continue # Continue to process body/MEND

            elif potential_macro_name == 'MEND' and in_macro_definition:
                print(f"Line {line_num+1}: Ending definition for '{current_macro_name}'")
                mdt.append(line_strip) # Store MEND
                in_macro_definition = False
                current_macro_name = None
                continue

            elif in_macro_definition:
                # Store lines inside definition, substituting formal args
                processed_line = line # Keep original indentation
                if current_macro_name and current_macro_name in ala_definition_structure:
                     temp_line = line_strip # Work with stripped for replacement logic
                     for formal_arg, positional_marker in ala_definition_structure[current_macro_name].items():
                         # Use regex for safer replacement (word boundaries)
                         temp_line = re.sub(r'\b&' + re.escape(formal_arg) + r'\b', positional_marker, temp_line)
                     # Reconstruct line with original indentation if possible
                     leading_whitespace = line[:len(line) - len(line.lstrip())]
                     processed_line = leading_whitespace + temp_line

                mdt.append(processed_line)
                continue # Don't add definition lines to output code

            # --- Handling Expansion ---
            elif potential_macro_name in mnt and not in_macro_definition:
                # Found a macro call
                print(f"Line {line_num+1}: Expanding Macro Call '{line_strip}'")
                macro_info = mnt[potential_macro_name]
                mdt_start_index = macro_info['mdt_index']
                num_expected_args = macro_info['num_args']

                actual_args_str = rest_of_line
                actual_args = [arg.strip() for arg in actual_args_str.split(',') if arg.strip()] if actual_args_str else []

                if len(actual_args) != num_expected_args:
                    error_msg = f"; Error Line {line_num+1}: Macro '{potential_macro_name}' expects {num_expected_args} args, got {len(actual_args)}."
                    print(error_msg)
                    output_code.append(error_msg)
                    continue

                call_ala = {f"#{i+1}": actual_args[i] for i in range(len(actual_args))}

                # Expand from MDT
                mdt_current_index = mdt_start_index + 1 # Start after prototype
                while mdt_current_index < len(mdt):
                    mdt_line = mdt[mdt_current_index] # Keep original line from MDT
                    mdt_line_strip = mdt_line.strip()

                    if mdt_line_strip == 'MEND':
                        break

                    expanded_line = mdt_line # Start with original line from MDT
                    # Substitute positional markers with actual arguments from call_ala
                    for positional, actual in call_ala.items():
                         # Use simple replace on the potentially indented line
                         expanded_line = expanded_line.replace(positional, actual)

                    output_code.append(expanded_line) # Add expanded line to output
                    mdt_current_index += 1
                continue # Finished expanding this call

            else:
                 # Regular assembly instruction or comment
                 if not in_macro_definition: # Ensure not inside definition
                    output_code.append(line) # Add non-macro line to output

        except StopIteration:
            break # End of source code input

    if in_macro_definition:
         print("Error: Reached end of file while still in macro definition for", current_macro_name)


# --- Example Usage ---
macro_source_single_pass = [
    "MACRO",            # Line 1
    "INCR &MEM, ®",  # Line 2 (Prototype)
    " MOVER ®, &MEM", # Line 3
    " ADD ®, ='1'",  # Line 4
    " MOVEM ®, &MEM", # Line 5
    "MEND",             # Line 6
    "",                 # Line 7
    "START 100",        # Line 8
    " INCR A, AREG",    # Line 9 (Call INCR)
    " INCR B, BREG",    # Line 10 (Call INCR)
    "",                 # Line 11
    "MACRO",            # Line 12
    "DECR &X",          # Line 13 (Prototype)
    " MOVER AREG, &X",  # Line 14
    " SUB AREG, ='1'",  # Line 15
    " MOVEM AREG, &X",  # Line 16
    "MEND",             # Line 17
    "",                 # Line 18
    " DECR C",          # Line 19 (Call DECR)
    " STOP",            # Line 20
    "A DS 1",           # Line 21
    "B DS 1",           # Line 22
    "C DS 1",           # Line 23
    " END"              # Line 24
]

process_source(macro_source_single_pass)

print("\n--- Macro Name Table (MNT) ---")
df_mnt_sp = pd.DataFrame.from_dict(mnt, orient='index')
if not df_mnt_sp.empty: print(df_mnt_sp)
else: print("(empty)")

print("\n--- Macro Definition Table (MDT) ---")
print(f"{'Index':<6}{'Definition Line'}")
print("-" * 40)
for i, line in enumerate(mdt):
    print(f"{i:<6}{line}")

print("\n--- Final Output Code (After Expansion) ---")
for line in output_code:
    print(line)

</code></pre>
                 </div>
            </div>

        </div>


        <!-- ==========================
             FIRST & FOLLOW SETS
             ========================== -->
        <div class="code-container">
            <h2 class="text-2xl">3. First & Follow Sets</h2>

            <!-- First Set -->
            <div>
                <h3 class="text-xl">3a. Calculate First Set</h3>
                <p>Computes the First set for each non-terminal in a given context-free grammar. Handles epsilon productions and recursion.</p>
                 <div class="run-command">
                    <strong>Language:</strong> Python<br>
                    <strong>Execution:</strong> <code>python first_set.py</code> (Save code as this file)
                </div>
                <div class="code-block-container">
                    <button class="copy-btn" data-target-id="code-firstset">Copy</button>
                    <pre id="code-firstset"><code class="language-python">
from collections import defaultdict

# Global dictionaries to store grammar, First sets, and calculation state
grammar = defaultdict(list)
first_sets = defaultdict(set)
# visited helps detect cycles/left-recursion during a *single* calculate_first call chain
# calculating tracks which non-terminals' First sets are currently being computed overall
visited = set()
calculating = set()

# Epsilon symbol (can be changed)
EPSILON = '#'

def add_production(non_terminal, production):
    """Adds a production rule to the grammar."""
    grammar[non_terminal].append(production)

def calculate_first(symbol):
    """Recursively calculates the First set for a given symbol (terminal or non-terminal)."""
    global first_sets, grammar, visited, calculating, EPSILON

    # If First set already computed and finalized, return it
    if symbol in first_sets and symbol not in calculating:
        return first_sets[symbol]

    # Base case: If symbol is a terminal, its First set is itself
    if not symbol.isupper(): # Assuming non-terminals are uppercase
        return {symbol}

    # If currently computing this symbol (cycle detected in this call stack)
    if symbol in visited:
        # This indicates left recursion for the current path.
        # A robust solution requires grammar transformation.
        # Here, we return an empty set for this path to avoid infinite loop,
        # but the overall calculation might still proceed via other paths.
        print(f"Warning: Left recursion detected involving {symbol}. Result might be incomplete without grammar transformation.")
        return set()

    # If calculation started but not finished (indicates dependency loop)
    if symbol in calculating:
         # We are waiting for this symbol's calculation to finish.
         # Return the current (potentially incomplete) set for now.
         # The final result will be settled when the outer call finishes.
        return first_sets[symbol]

    visited.add(symbol)
    calculating.add(symbol)
    current_first_set = set()

    # Iterate through all productions for this non-terminal
    for production in grammar.get(symbol, []):
        # Handle empty production (epsilon) directly associated with the symbol
        if not production: # Check if production is empty string "" or list [] etc.
            current_first_set.add(EPSILON)
            continue
        # Handle explicit epsilon symbol '#' in the production
        if production == EPSILON:
             current_first_set.add(EPSILON)
             continue

        # Process symbols in the production
        rhs_symbol_index = 0
        while rhs_symbol_index < len(production):
            rhs_symbol = production[rhs_symbol_index]
            first_of_rhs = calculate_first(rhs_symbol)

            # Add everything except epsilon from First(rhs_symbol)
            current_first_set.update(first_of_rhs - {EPSILON})

            # If epsilon is not in First(rhs_symbol), stop for this production
            if EPSILON not in first_of_rhs:
                break

            # If epsilon is present, move to the next symbol in the production
            rhs_symbol_index += 1
        else:
            # If we reached the end of the production and all symbols had epsilon, add epsilon
            current_first_set.add(EPSILON)

    visited.remove(symbol) # Finished this specific recursive path
    # Update the global set. If it changes, other dependent calculations might need re-evaluation (handled by iterative approach if needed)
    first_sets[symbol].update(current_first_set)
    calculating.remove(symbol) # Mark calculation as complete for this symbol
    return first_sets[symbol]

# --- Iterative approach to handle mutual recursion ---
def compute_all_first_sets(non_terminals_list):
    """Computes First sets iteratively until no changes occur."""
    changed = True
    while changed:
        changed = False
        for nt in non_terminals_list:
            original_set = first_sets[nt].copy()
            # Clear visited for each top-level call to allow exploring different paths
            visited.clear()
            calculate_first(nt)
            if first_sets[nt] != original_set:
                changed = True

# --- Example Grammar ---
# E -> T E'
# E' -> + T E' | #
# T -> F T'
# T' -> * F T' | #
# F -> ( E ) | id
grammar_input = {
    'E': ['TE\''],
    'E\'': ['+TE\'', EPSILON], # Using # for epsilon
    'T': ['FT\''],
    'T\'': ['*FT\'', EPSILON],
    'F': ['(E)', 'id']
}

# Populate the grammar dictionary
non_terminals_list = list(grammar_input.keys())
for nt, productions in grammar_input.items():
    for prod in productions:
        # Represent production as list of symbols for easy iteration
        add_production(nt, list(prod) if prod != EPSILON else [EPSILON])


# Calculate First sets for all non-terminals iteratively
print("--- Calculating First Sets ---")
compute_all_first_sets(non_terminals_list)

# Print the results
print("\n--- First Sets ---")
for non_terminal in sorted(non_terminals_list):
    print(f"First({non_terminal}) = {{{', '.join(sorted(list(first_sets[non_terminal])))}}}")

</code></pre>
                </div>
            </div>

            <!-- Follow Set -->
            <div>
                <h3 class="text-xl">3b. Calculate Follow Set</h3>
                <p>Computes the Follow set for each non-terminal in a given context-free grammar, using pre-calculated First sets.</p>
                 <div class="run-command">
                    <strong>Language:</strong> Python<br>
                    <strong>Prerequisite:</strong> Requires the First set calculation code (or results) from 3a.<br>
                    <strong>Execution:</strong> <code>python follow_set.py</code> (Save code as this file, ensure first_set logic is available or included)
                </div>
                 <div class="code-block-container">
                     <button class="copy-btn" data-target-id="code-followset">Copy</button>
                    <pre id="code-followset"><code class="language-python">
from collections import defaultdict

# --- Assume First Set Calculation Logic is Available (or include it here) ---
# --- We need the `grammar`, `first_sets`, `EPSILON` variables populated ---

# Global dictionaries
grammar = defaultdict(list)
first_sets = defaultdict(set) # Assume this is populated correctly
follow_sets = defaultdict(set)
non_terminals_global = set() # Keep track of all non-terminals
start_symbol = None
EPSILON = '#'
EOF = '$' # End of input marker

# --- Functions needed (can be imported or defined here) ---
def add_production(non_terminal, production_list): # Expects production as a list of symbols
    """Adds a production rule to the grammar."""
    global non_terminals_global, start_symbol
    grammar[non_terminal].append(production_list)
    non_terminals_global.add(non_terminal)
    if start_symbol is None:
        start_symbol = non_terminal # Assume first non-terminal added

def calculate_first_for_string(symbols_list):
    """Calculates the First set for a list/string of symbols alpha."""
    # Needs access to the pre-calculated `first_sets` global dictionary
    result_first = set()
    idx = 0
    while idx < len(symbols_list):
        symbol = symbols_list[idx]
        # Get First(symbol). Terminals have First(symbol) = {symbol}
        first_of_symbol = set()
        if symbol in first_sets:
             first_of_symbol = first_sets[symbol]
        elif not symbol.isupper() and symbol != EPSILON: # It's a terminal
             first_of_symbol = {symbol}
        elif symbol == EPSILON:
             first_of_symbol = {EPSILON} # Should ideally not be in production list directly
        else:
            print(f"Error: First set for symbol '{symbol}' not found!")
            # Handle error or assume empty set? For safety, let's stop.
            return set() # Cannot proceed without First set

        result_first.update(first_of_symbol - {EPSILON})

        if EPSILON not in first_of_symbol:
            break # Epsilon not present, stop
        idx += 1
    else:
        # If loop finished (all symbols had epsilon in their First set), add epsilon
        result_first.add(EPSILON)
    return result_first

def calculate_follow_sets():
    """Calculates Follow sets for all non-terminals in the grammar."""
    global follow_sets, grammar, non_terminals_global, start_symbol, first_sets, EOF

    if not start_symbol:
        print("Error: Start symbol not set.")
        return

    # Initialize Follow sets
    for nt in non_terminals_global:
        follow_sets[nt] = set()

    # Rule 1: Place EOF in Follow(S), where S is the start symbol
    follow_sets[start_symbol].add(EOF)

    # Rules 2 & 3: Iterate until no changes occur in any Follow set
    changed = True
    while changed:
        changed = False
        # Iterate through each production A -> alpha
        for non_terminal_A in grammar:
            for production in grammar[non_terminal_A]: # production is a list of symbols
                # Iterate through symbols B in alpha: A -> prefix B suffix
                for i in range(len(production)):
                    symbol_B = production[i]

                    # Check if B is a non-terminal
                    if symbol_B in non_terminals_global:
                        # Find suffix (beta in the rule A -> alpha B beta)
                        suffix_beta = production[i+1:]

                        # Rule 2: A -> alpha B beta, Follow(B) includes First(beta) - {epsilon}
                        if suffix_beta: # If beta is not empty
                            first_of_beta = calculate_first_for_string(suffix_beta)
                            original_size = len(follow_sets[symbol_B])
                            added_terminals = first_of_beta - {EPSILON}
                            if added_terminals:
                                follow_sets[symbol_B].update(added_terminals)
                                if len(follow_sets[symbol_B]) > original_size:
                                    changed = True

                        # Rule 3: A -> alpha B, or A -> alpha B beta where First(beta) contains epsilon
                        if not suffix_beta or EPSILON in calculate_first_for_string(suffix_beta):
                            original_size = len(follow_sets[symbol_B])
                            # Follow(B) includes Follow(A)
                            if non_terminal_A in follow_sets: # Ensure Follow(A) exists
                                follow_sets[symbol_B].update(follow_sets[non_terminal_A])
                                if len(follow_sets[symbol_B]) > original_size:
                                    changed = True

# --- Example Grammar & Pre-calculated First Sets ---
# MUST match the grammar used for First sets
grammar_input_follow = {
    'E': ['TE\''],
    'E\'': ['+TE\'', EPSILON],
    'T': ['FT\''],
    'T\'': ['*FT\'', EPSILON],
    'F': ['(E)', 'id']
}
# Assume these First sets were calculated previously and are correct
first_sets_input = {
    'E': {'(', 'id'}, 'E\'': {'+', EPSILON},
    'T': {'(', 'id'}, 'T\'': {'*', EPSILON},
    'F': {'(', 'id'},
    # Include terminals as well for calculate_first_for_string
    '+': {'+'}, '*': {'*'}, '(': {'('}, ')': {')'}, 'id': {'id'}
}

# Populate grammar and first sets
grammar = defaultdict(list)
first_sets = defaultdict(set, first_sets_input)
non_terminals_global = set()
start_symbol = None
for nt, productions in grammar_input_follow.items():
    for prod_str in productions:
        prod_list = list(prod_str) if prod_str != EPSILON else [EPSILON]
        # Special case for E': Need to handle ['+','T','E\''] and [EPSILON]
        if prod_str == '+TE\'':
            add_production(nt, ['+', 'T', 'E\''])
        elif prod_str == '*FT\'':
             add_production(nt, ['*', 'F', 'T\''])
        elif prod_str == '(E)':
             add_production(nt, ['(', 'E', ')'])
        elif prod_str == EPSILON:
             add_production(nt, [EPSILON]) # Represent epsilon production
        else: # Handles 'TE\'', 'FT\'', 'id'
             add_production(nt, list(prod_str))


# Calculate Follow sets
print("--- Calculating Follow Sets ---")
calculate_follow_sets()

# Print the results
print("\n--- Follow Sets ---")
for nt in sorted(list(non_terminals_global)): # Sort for consistent output
    print(f"Follow({nt}) = {{{', '.join(sorted(list(follow_sets[nt])))}}}")

</code></pre>
                 </div>
            </div>
        </div>

        <!-- ==========================
             LEXICAL ANALYZER (Handwritten)
             ========================== -->
        <div class="code-container">
            <h2 class="text-2xl">4. Handwritten Lexical Analyzer</h2>

            <!-- Keywords, Identifiers, Symbols -->
            <div>
                <h3 class="text-xl">4a. Identify Keywords, Identifiers, Symbols</h3>
                <p>A simple Python lexer that identifies basic tokens like keywords, identifiers (variables), and symbols/operators.</p>
                 <div class="run-command">
                    <strong>Language:</strong> Python<br>
                    <strong>Execution:</strong> <code>python lexer_kwd_id_sym.py</code> (Save code as this file)
                </div>
                 <div class="code-block-container">
                     <button class="copy-btn" data-target-id="code-lexer-4a">Copy</button>
                    <pre id="code-lexer-4a"><code class="language-python">
import re

# Define token types
T_KEYWORD = 'KEYWORD'
T_IDENTIFIER = 'IDENTIFIER'
T_SYMBOL = 'SYMBOL'
T_UNKNOWN = 'UNKNOWN'
T_EOF = 'EOF' # End of File/Input

# Regular expressions for token patterns
# Order matters! Keywords should be checked before identifiers.
KEYWORDS = {'if', 'else', 'while', 'for', 'int', 'float', 'char', 'return', 'void', 'main'}
SYMBOLS = r'[(){};,=+\-*/<>&|]' # Group symbols

# More robust token spec using functions or separate checks after IDENTIFIER match
token_specification = [
    ('NUMBER',    r'\d+(\.\d*)?'),           # Integer or float
    ('IDENTIFIER',r'[A-Za-z_][A-Za-z0-9_]*'),   # Identifiers
    ('SYMBOL',    SYMBOLS),                  # Use defined symbols regex
    ('SKIP',      r'[ \t\n]+'),                # Skip whitespace and newlines
    ('MISMATCH',  r'.'),                       # Any other character is a mismatch
]

# Compile regex patterns
token_regex = '|'.join(f'(?P<{pair[0]}>{pair[1]})' for pair in token_specification)
compiled_regex = re.compile(token_regex)

def tokenize(code):
    """Generates tokens from the input code string."""
    line_num = 1
    pos = 0
    while pos < len(code):
        match = compiled_regex.match(code, pos)
        if not match:
            print(f"Lexer Error: Unexpected character '{code[pos]}' at line {line_num}, pos {pos}")
            pos += 1 # Skip the problematic character
            continue

        kind = match.lastgroup # Type of token found (e.g., 'IDENTIFIER')
        value = match.group()   # The actual text matched
        pos = match.end()       # Move position to the end of the match

        if kind == 'SKIP':
            line_num += value.count('\n') # Update line number
            continue
        elif kind == 'MISMATCH':
            yield (T_UNKNOWN, value, line_num) # Report unknown characters
        elif kind == 'IDENTIFIER':
            # Check if it's a keyword after matching as an identifier
            if value in KEYWORDS:
                yield (T_KEYWORD, value, line_num)
            else:
                yield (T_IDENTIFIER, value, line_num)
        else: # NUMBER, SYMBOL
             yield (kind, value, line_num) # Use kind directly
             line_num += value.count('\n') # Count newlines within multiline tokens (if any)


    yield (T_EOF, '', line_num) # Signal end of input


# --- Example Usage ---
source_code_lex1 = """
int main() {
    int count = 0;
    float value = 10.5; // Example with float
    if (count > 0) {
        value = value + 1; /* Symbol + */
    }
    return 0;
}
"""

print("--- Tokenizing Code (Keywords, Identifiers, Symbols) ---")
print(f"{'Type':<15}{'Value':<15}{'Line':<5}")
print("-" * 35)

for token in tokenize(source_code_lex1):
    token_type, token_value, token_line = token
    print(f"{token_type:<15}{token_value:<15}{token_line:<5}")

</code></pre>
                 </div>
            </div>

            <!-- Numbers, Identifiers, Preprocessor -->
             <div>
                <h3 class="text-xl">4b. Identify Numbers, Identifiers, Preprocessor Directives</h3>
                <p>Extends the lexer to recognize integer and floating-point numbers and simple preprocessor directives (like `#include`).</p>
                 <div class="run-command">
                    <strong>Language:</strong> Python<br>
                    <strong>Execution:</strong> <code>python lexer_num_id_pre.py</code> (Save code as this file)
                </div>
                <div class="code-block-container">
                    <button class="copy-btn" data-target-id="code-lexer-4b">Copy</button>
                    <pre id="code-lexer-4b"><code class="language-python">
import re

# Define token types
T_PREPROCESSOR = 'PREPROCESSOR'
T_KEYWORD = 'KEYWORD'
T_IDENTIFIER = 'IDENTIFIER'
T_NUMBER = 'NUMBER'
T_SYMBOL = 'SYMBOL'
T_STRING = 'STRING'
T_UNKNOWN = 'UNKNOWN'
T_EOF = 'EOF'

# Regex patterns
KEYWORDS_V2 = {'if', 'else', 'while', 'for', 'int', 'float', 'char', 'return', 'void', 'main', 'include', 'define'}
SYMBOLS_V2 = r'[(){};,=+\-*/<>&|]' # Can expand this (e.g., +=, -=, ==, !=)

token_specification_v2 = [
    ('PREPROCESSOR', r'^\#.*'),                 # Lines starting with # (catches whole line)
    ('NUMBER',       r'\d+(\.\d*)?|\.\d+'),     # Integer or float
    ('STRING',       r'\"([^\\\"]|\\.)*\"'),    # Basic string literal
    ('IDENTIFIER',   r'[A-Za-z_][A-Za-z0-9_]*'), # Identifiers
    ('SYMBOL',       SYMBOLS_V2),               # Use defined symbols regex
    ('NEWLINE',      r'\n'),                    # Track newlines explicitly
    ('SKIP',         r'[ \t]+'),                # Skip spaces and tabs only
    ('MISMATCH',     r'.'),                     # Any other character
]

# Compile regex patterns
# Need MULTILINE flag for ^ preprocessor anchor
token_regex_v2 = '|'.join(f'(?P<{pair[0]}>{pair[1]})' for pair in token_specification_v2)
compiled_regex_v2 = re.compile(token_regex_v2, re.MULTILINE)

def tokenize_v2(code):
    """Generates tokens including numbers and preprocessor directives."""
    line_num = 1
    pos = 0
    while pos < len(code):
        match = compiled_regex_v2.match(code, pos)
        if not match:
            pos += 1
            continue

        kind = match.lastgroup
        value = match.group()
        pos = match.end()

        if kind == 'SKIP':
            continue
        elif kind == 'NEWLINE':
            line_num += 1
            continue # Don't yield newline tokens usually
        elif kind == 'MISMATCH':
            yield (T_UNKNOWN, value, line_num)
        elif kind == 'IDENTIFIER':
            if value in KEYWORDS_V2:
                yield (T_KEYWORD, value, line_num)
            else:
                yield (T_IDENTIFIER, value, line_num)
        else: # PREPROCESSOR, NUMBER, STRING, SYMBOL
             yield (kind, value, line_num)
             # Preprocessor directives consume the newline, update line counter
             if kind == 'PREPROCESSOR':
                 line_num += value.count('\n')


    yield (T_EOF, '', line_num)


# --- Example Usage ---
source_code_lex2 = """
#include <stdio.h>
#define MAX 100

int main() {
    int counter = 0;
    float limit = 99.5;
    char message[] = "Hello\\nWorld!"; // String literal

    if (counter < MAX) {
        printf(message); // Function call identifier
    }
    return 0; // Number
}
"""

print("--- Tokenizing Code (Numbers, Identifiers, Preprocessor) ---")
print(f"{'Type':<15}{'Value':<25}{'Line':<5}")
print("-" * 50)

for token in tokenize_v2(source_code_lex2):
    token_type, token_value, token_line = token
    # Limit display length of long tokens like preprocessor lines
    display_value = token_value.strip() # Strip whitespace for display
    display_value = (display_value[:22] + '...') if len(display_value) > 25 else display_value
    print(f"{token_type:<15}{display_value:<25}{token_line:<5}")

</code></pre>
                </div>
            </div>

             <!-- Identifiers, Symbols, Remove Comments -->
            <div>
                <h3 class="text-xl">4c. Identify Identifiers, Symbols & Remove Comments</h3>
                <p>Focuses on identifying identifiers and symbols while explicitly removing single-line (`//`) and multi-line (`/* ... */`) comments.</p>
                 <div class="run-command">
                    <strong>Language:</strong> Python<br>
                    <strong>Execution:</strong> <code>python lexer_id_sym_comment.py</code> (Save code as this file)
                </div>
                 <div class="code-block-container">
                    <button class="copy-btn" data-target-id="code-lexer-4c">Copy</button>
                    <pre id="code-lexer-4c"><code class="language-python">
import re

# Define token types
T_IDENTIFIER = 'IDENTIFIER'
T_SYMBOL = 'SYMBOL'
T_UNKNOWN = 'UNKNOWN'
T_EOF = 'EOF'

# Regex patterns
# Improved comment handling (especially nested /* */ which this simple regex won't handle)
# This regex assumes non-nested multi-line comments
token_specification_v3 = [
    ('COMMENT',       r'/\*.*?\*/|//.*'),        # Combine multi (non-greedy) and single
    ('IDENTIFIER',    r'[A-Za-z_][A-Za-z0-9_]*'),# Identifiers
    ('SYMBOL',        r'[(){};,=+\-*/<>&|]'),   # Single-character symbols
    ('NEWLINE',       r'\n'),                   # Keep track of lines
    ('SKIP',          r'[ \t]+'),               # Skip spaces and tabs
    ('MISMATCH',      r'.'),                    # Any other character
]

# Compile regex
# Need DOTALL flag for multi-line comment potentially spanning lines
token_regex_v3 = '|'.join(f'(?P<{pair[0]}>{pair[1]})' for pair in token_specification_v3)
compiled_regex_v3 = re.compile(token_regex_v3, re.DOTALL)

def tokenize_and_filter(code):
    """Generates tokens (ID, SYMBOL) and filters comments/whitespace."""
    line_num = 1
    tokens = []
    pos = 0
    while pos < len(code):
        match = compiled_regex_v3.match(code, pos)
        if not match:
            # This case indicates an issue with the regex or input
            print(f"Error: Lexer stuck at pos {pos} on line {line_num}")
            pos += 1 # Try to advance
            continue

        kind = match.lastgroup
        value = match.group()
        pos = match.end()

        if kind == 'NEWLINE':
            line_num += 1
            continue # Don't yield newline token
        elif kind == 'SKIP' or kind == 'COMMENT':
            line_num += value.count('\n') # Count newlines in multi-line comments/skipped
            continue # Skip comments and whitespace
        elif kind == 'IDENTIFIER':
            tokens.append((T_IDENTIFIER, value, line_num))
        elif kind == 'SYMBOL':
            tokens.append((T_SYMBOL, value, line_num))
        elif kind == 'MISMATCH':
            tokens.append((T_UNKNOWN, value, line_num))

    tokens.append((T_EOF, '', line_num))
    return tokens

# --- Example Usage ---
source_code_lex3 = """
/* Multi-line
   comment example */
int main() {
    int value = 5; // Single line comment
    char symbol = '+';
    value = value * (symbol - 1); /* Another comment */
    return 0;
}
"""

print("--- Tokenizing Code (ID, Symbol, Removing Comments) ---")
print(f"{'Type':<15}{'Value':<15}{'Line':<5}")
print("-" * 35)

filtered_tokens = tokenize_and_filter(source_code_lex3)
for token in filtered_tokens:
    token_type, token_value, token_line = token
    print(f"{token_type:<15}{token_value:<15}{token_line:<5}")

# Also show the code with comments removed (simple reconstruction)
print("\n--- Code with Comments Removed (Reconstructed) ---")
reconstructed_code = ""
last_line = 1
for token_type, token_value, token_line in filtered_tokens:
    if token_type == T_EOF: break
    # Add newlines based on line number difference
    if token_line > last_line:
        reconstructed_code += "\n" * (token_line - last_line)
        reconstructed_code += " " * 4 # Basic indentation
    elif reconstructed_code and not reconstructed_code.endswith('\n'):
         reconstructed_code += " " # Space between tokens on same line

    reconstructed_code += token_value
    last_line = token_line

print(reconstructed_code.strip())

</code></pre>
                 </div>
            </div>
        </div>

         <!-- ==========================
             LEXICAL ANALYZER (LEX Tool)
             ========================== -->
        <div class="code-container">
            <h2 class="text-2xl">5. Automated Lexical Analyzer (LEX Tool)</h2>
            <p>Demonstrates the structure of a `.l` file for use with the `flex` (or `lex`) tool to generate a C-based lexical analyzer.</p>
             <div class="run-command">
                <strong>Language:</strong> C / Lex Syntax<br>
                <strong>Tools Required:</strong> <code>flex</code> (or <code>lex</code>) and a C compiler (like <code>gcc</code>)<br>
                <strong>Steps:</strong>
                <ol class="list-decimal list-inside ml-4">
                    <li>Save the code below as <code>mylexer.l</code>.</li>
                    <li>Generate C code: <code>flex mylexer.l</code> (This creates <code>lex.yy.c</code>).</li>
                    <li>Compile the C code: <code>gcc lex.yy.c -o mylexer -lfl</code> (<code>-lfl</code> might be needed).</li>
                    <li>Prepare an input file (e.g., <code>input.txt</code>) with code to analyze.</li>
                    <li>Run the lexer: <code>./mylexer < input.txt</code></li>
                </ol>
            </div>
             <div class="code-block-container">
                <button class="copy-btn" data-target-id="code-lex-tool">Copy</button>
                <pre id="code-lex-tool"><code class="language-c">
/* mylexer.l - Example Lex file */
%{
// C declarations section
#include <stdio.h>

// Define token types (optional, often done via yacc/bison header)
// These are just examples for the printf output
#define T_KEYWORD 1
#define T_IDENTIFIER 2
#define T_NUMBER 3
#define T_SYMBOL 4
#define T_STRING 5
#define T_COMMENT 6 // For recognizing, maybe skipping
#define T_PREPROCESSOR 7
#define T_WHITESPACE 8 // Often skipped
#define T_UNKNOWN 9
%}

/* Definitions for regular expressions (optional aliases) */
digit       [0-9]
letter      [A-Za-z_]
identifier  {letter}({letter}|{digit})*
number      {digit}+(\.{digit}+)?([Ee][+-]?{digit}+)? /* Integer, float, basic scientific */
newline     \n
whitespace  [ \t]+

/* C Keywords (add more as needed) */
keyword     if|else|while|for|int|float|char|return|void|main|include|define|struct|typedef

/* Symbols (add more as needed, handle multi-char like ==, !=, += etc.) */
symbol      "{"|"}"|"("|")"|";"|","|"="|"++"|"--"|"+"|"-"|"*"|"/"|"<"|">"|"&"|"|"|"!"|"=="|"!="|"<="|">="|"&&"|"||"

/* String literal (basic) */
string      \"([^"\\\n]|\\.)*\"

/* Comments */
comment_single \/\/[^\n]*
comment_multi  \/\*([^*]|\*+[^*/])*\*+\/

/* Preprocessor */
preprocessor ^#[^\n]*


%%
/* Rules Section: Pattern -> Action */
/* Order is important! Keywords before identifiers, longer symbols before shorter */

{preprocessor}   { printf("TOKEN(%3d): PREPROCESSOR\t'%s'\n", yylineno, yytext); /* return T_PREPROCESSOR; */ }

{comment_single} { /* printf("COMMENT(%3d): SINGLE_LINE\t'%s'\n", yylineno, yytext); */ /* Skip comment */ }
{comment_multi}  { /* printf("COMMENT(%3d): MULTI_LINE\t'%s'\n", yylineno, yytext); */ /* Skip comment */ }

{keyword}        { printf("TOKEN(%3d): KEYWORD\t\t'%s'\n", yylineno, yytext); /* return T_KEYWORD; */ }
{identifier}     { printf("TOKEN(%3d): IDENTIFIER\t'%s'\n", yylineno, yytext); /* return T_IDENTIFIER; */ }
{number}         { printf("TOKEN(%3d): NUMBER\t\t'%s'\n", yylineno, yytext); /* return T_NUMBER; */ }
{string}         { printf("TOKEN(%3d): STRING\t\t'%s'\n", yylineno, yytext); /* return T_STRING; */ }
{symbol}         { printf("TOKEN(%3d): SYMBOL\t\t'%s'\n", yylineno, yytext); /* return T_SYMBOL; */ }


{whitespace}     { /* Skip whitespace - no action */ }
{newline}        { yylineno++; /* Increment line number */ }

.                { printf("TOKEN(%3d): UNKNOWN\t\t'%s'\n", yylineno, yytext); /* return T_UNKNOWN; */ }

%%
/* C Code Section (User routines) */

int yywrap() {
    // Called at end of input. Return 1 to indicate done.
    return 1;
}

int main(int argc, char *argv[]) {
    // Optional: Open a file if provided as argument
    if (argc > 1) {
        FILE *file = fopen(argv[1], "r");
        if (!file) {
            perror(argv[1]);
            return 1;
        }
        // Redirect flex's input to the file
        yyin = file;
    }
    // If no file argument, yyin defaults to stdin

    printf("--- Lexical Analysis using Flex ---\n");
    printf("%-15s %-20s %s\n", "Token Type", "Value", "Line No.");
    printf("--------------------------------------------------\n");
    yylex(); // Start the lexer
    printf("--------------------------------------------------\n");
    printf("--- Analysis Complete ---\n");

    // Close file if opened
    if (yyin != stdin && yyin != NULL) { // Check if yyin was changed and is not NULL
        fclose(yyin);
    }

    return 0;
}

</code></pre>
             </div>
        </div>

        <!-- ==========================
             CODE OPTIMIZATION
             ========================== -->
        <div class="code-container">
            <h2 class="text-2xl">6. Code Optimization Techniques</h2>

            <!-- Algebraic Simp / Common Subexpression -->
            <div>
                <h3 class="text-xl">6a. Algebraic Simplification & Common Subexpression Elimination</h3>
                <p>Basic implementation using string replacement for simple algebraic rules (like `x+0`) and identifying repeated expressions.</p>
                 <div class="run-command">
                    <strong>Language:</strong> Python<br>
                    <strong>Execution:</strong> <code>python code_opt_alg_cse.py</code> (Save code as this file)
                </div>
                 <div class="code-block-container">
                     <button class="copy-btn" data-target-id="code-optimize-6a">Copy</button>
                    <pre id="code-optimize-6a"><code class="language-python">
import re

def algebraic_simplification(code_lines):
    """Applies simple algebraic simplification rules."""
    optimized_lines = []
    print("--- Applying Algebraic Simplification ---")
    for line in code_lines:
        original_line = line
        # Rule: x = y + 0  or  x = 0 + y  -> x = y
        line = re.sub(r'=\s*([\w.\(\)]+)\s*\+\s*0\b', r'= \1', line) # y + 0 (Handles temp vars like (0))
        line = re.sub(r'=\s*0\s*\+\s*([\w.\(\)]+)\b', r'= \1', line) # 0 + y

        # Rule: x = y * 1  or  x = 1 * y -> x = y
        line = re.sub(r'=\s*([\w.\(\)]+)\s*\*\s*1\b', r'= \1', line) # y * 1
        line = re.sub(r'=\s*1\s*\*\s*([\w.\(\)]+)\b', r'= \1', line) # 1 * y

        # Rule: x = y * 0 or x = 0 * y -> x = 0
        line = re.sub(r'=\s*[\w.\(\)]+\s*\*\s*0\b', r'= 0', line) # y * 0
        line = re.sub(r'=\s*0\s*\*\s*[\w.\(\)]+\b', r'= 0', line) # 0 * y

        # Rule: x = y - 0 -> x = y
        line = re.sub(r'=\s*([\w.\(\)]+)\s*-\s*0\b', r'= \1', line) # y - 0

         # Rule: x = y / 1 -> x = y
        line = re.sub(r'=\s*([\w.\(\)]+)\s*/\s*1\b', r'= \1', line) # y / 1

        optimized_lines.append(line)
        if line != original_line:
            print(f"Simplified: '{original_line.strip()}' -> '{line.strip()}'")

    return optimized_lines


def common_subexpression_elimination(code_lines):
    """Performs basic common subexpression elimination within basic blocks (here, lines)."""
    optimized_lines = []
    expressions = {} # Store expression -> temp_variable mapping
    temp_count = 0
    print("\n--- Applying Common Subexpression Elimination ---")

    final_optimized_block = [] # Build the final block here

    for line in code_lines:
        original_line = line
        # Basic pattern matching for assignment: var = operand1 op operand2
        match = re.match(r'\s*(\w+)\s*=\s*([\w.\(\)]+)\s*([+\-*/])\s*([\w.\(\)]+)\s*;?\s*$', line)
        is_complex_assignment = bool(match)

        if is_complex_assignment:
            target_var = match.group(1).strip()
            operand1 = match.group(2).strip()
            op = match.group(3).strip()
            operand2 = match.group(4).strip()
            # Canonical expression form (e.g., sort operands for commutative ops)
            if op in ['+', '*'] and operand1 > operand2:
                 expression = f"{operand2} {op} {operand1}" # Sort operands
            else:
                 expression = f"{operand1} {op} {operand2}"

            if expression in expressions:
                # Found common subexpression
                temp_var = expressions[expression]
                line = f"{target_var} = {temp_var}" # Replace with assignment from temp
                print(f"CSE: Replaced '{original_line.strip()}' with '{line.strip()}' (using {temp_var})")
                final_optimized_block.append(line) # Add the modified assignment
            else:
                 # New expression encountered, store it
                 temp_count += 1
                 new_temp = f"t{temp_count}"
                 expressions[expression] = new_temp
                 # Insert the temp calculation *before* the current line
                 temp_calc_line = f"{new_temp} = {expression}"
                 final_optimized_block.append(temp_calc_line)
                 # Current line now uses the temp
                 line = f"{target_var} = {new_temp}"
                 final_optimized_block.append(line)
                 print(f"CSE: Introduced '{temp_calc_line}' for '{original_line.strip()}'")
        else:
            # Not a complex assignment, keep the line as is
             final_optimized_block.append(original_line)


    return final_optimized_block

# --- Example Usage ---
input_code_alg_cse = [
    "a = b + 0",      # Algebraic Simplification
    "c = d * 1",      # Algebraic Simplification
    "e = f * 0",      # Algebraic Simplification
    "x = y + z",      # Expression 1
    "p = y + z",      # Common Subexpression (should become p = t1)
    "q = z + y",      # Common Subexpression (commutative, should become q = t1)
    "r = p * 2",      # Uses result of CSE (depends on p or t1) -> t2 = t1 * 2; r = t2
    "s = y + z"       # Common Subexpression again (should become s = t1)
]

print("--- Original Code ---")
for l in input_code_alg_cse: print(l)

simplified_code = algebraic_simplification(input_code_alg_cse)
# Apply CSE iteratively until no more changes? For simplicity, one pass here.
final_code = common_subexpression_elimination(simplified_code)

print("\n--- Final Optimized Code ---")
for l in final_code:
    print(l.strip())

</code></pre>
                 </div>
            </div>

            <!-- Dead Code / Constant Prop -->
            <div>
                <h3 class="text-xl">6b. Dead Code Elimination & Constant Propagation</h3>
                <p>Simple simulation of removing unused variable assignments (dead code) and replacing variable usage with known constants.</p>
                 <div class="run-command">
                    <strong>Language:</strong> Python<br>
                    <strong>Execution:</strong> <code>python code_opt_dead_const.py</code> (Save code as this file)
                </div>
                <div class="code-block-container">
                    <button class="copy-btn" data-target-id="code-optimize-6b">Copy</button>
                    <pre id="code-optimize-6b"><code class="language-python">
import re
import ast # Abstract Syntax Trees can be more robust for analysis

def constant_propagation(code_lines):
    """Performs simple constant propagation using string replacement (limited)."""
    optimized_lines = []
    constants = {} # variable -> constant value (string representation)
    print("--- Applying Constant Propagation ---")

    for line in code_lines:
        original_line = line
        modified = False

        # Pattern: var = constant_literal ; (optional semicolon and whitespace)
        match_assign = re.match(r'\s*([a-zA-Z_]\w*)\s*=\s*(-?\d+(\.\d+)?)\s*;?\s*$', line)
        if match_assign:
            var = match_assign.group(1)
            value = match_assign.group(2)
            constants[var] = value # Store known constant
            print(f"  Found constant assignment: {var} = {value}")
            optimized_lines.append(line) # Keep assignment for now
            continue

        # Substitute known constants in expressions on RHS
        current_line = line
        # Split line at '=' to only modify RHS
        parts = current_line.split('=', 1)
        if len(parts) == 2:
            lhs = parts[0]
            rhs = parts[1]
            original_rhs = rhs # Keep original RHS for comparison
            for var, value in constants.items():
                # Use regex with word boundaries to replace variable occurrences on RHS
                rhs = re.sub(r'\b' + re.escape(var) + r'\b', value, rhs)

            if rhs != original_rhs:
                current_line = lhs + '= ' + rhs # Reconstruct line
                modified = True
                print(f"Propagated Const: '{original_line.strip()}' -> '{current_line.strip()}'")
        # else: line has no '=', substitute anywhere (less common for propagation)
        #    original_line_part = current_line
        #    for var, value in constants.items():
        #        current_line = re.sub(r'\b' + re.escape(var) + r'\b', value, current_line)
        #    if current_line != original_line_part: modified = True

        optimized_lines.append(current_line)

    return optimized_lines, constants

def dead_code_elimination(code_lines, constants_found):
    """Performs simple dead code elimination (unused assignments)."""
    # This is tricky with string processing. Using AST would be better.
    # Simple approach: track assigned variables and check if they are used later on RHS.
    used_vars = set()
    assignments = {} # target_var -> line_index

    # Pass 1: Identify used variables on RHS and track assignments
    print("\n--- Analyzing Variable Usage ---")
    for i, line in enumerate(code_lines):
        # Check LHS for assignment
        match_assign = re.match(r'\s*([a-zA-Z_]\w*)\s*=', line)
        if match_assign:
            target_var = match_assign.group(1)
            assignments[target_var] = i # Store index of last assignment
            print(f"  Line {i}: Assigns to '{target_var}'")

        # Check RHS for usage
        parts = line.split('=', 1)
        rhs = parts[1] if len(parts) == 2 else line # Consider whole line if no '='
        # Find potential variables used in RHS (simple identifier match)
        found_in_rhs = re.findall(r'\b([a-zA-Z_]\w*)\b', rhs)
        # Also consider variables used in print/return/conditions (very basic check)
        if 'print' in line or 'return' in line or 'if' in line or 'while' in line:
             found_in_rhs.extend(re.findall(r'\b([a-zA-Z_]\w*)\b', line))

        # Exclude the target variable itself from being marked as 'used' by its own assignment line
        target_on_this_line = match_assign.group(1) if match_assign else None
        for var in found_in_rhs:
             if var != target_on_this_line:
                 used_vars.add(var)
                 # print(f"  Line {i}: Uses '{var}'") # Can be verbose

    print(f"  Variables used on RHS or in output/conditions: {used_vars}")

    # Pass 2: Filter out lines assigning to unused variables
    optimized_lines = []
    print("\n--- Applying Dead Code Elimination ---")
    removed_count = 0
    for i, line in enumerate(code_lines):
        is_dead = False
        match_assign = re.match(r'\s*([a-zA-Z_]\w*)\s*=', line)
        if match_assign:
            target_var = match_assign.group(1)
            # Considered dead IF:
            # 1. It's the last assignment to this variable (i == assignments[target_var])
            # 2. The variable is NOT in the set of used variables
            if i == assignments.get(target_var, -1) and target_var not in used_vars:
                 is_dead = True
                 print(f"Dead Code: Removed '{line.strip()}' (variable '{target_var}' assigned but never used)")
                 removed_count += 1

        if not is_dead:
            optimized_lines.append(line)

    if removed_count == 0:
        print("No dead assignment code found with this simple analysis.")

    return optimized_lines


# --- Example Usage ---
input_code_dead_const = [
    "x = 5;",          # Constant definition
    "y = x + 2;",      # Use constant x -> y = 5 + 2
    "z = 10;",         # Another constant
    "a = y * z;",      # Use constants y, z -> a = 7 * 10
    "b = a - x;",      # Use constants a, x -> b = 70 - 5
    "dead_var = z + 1;",# Assignment to dead_var (never used)
    "c = y + 5;",      # Use constant y -> c = 7 + 5
    "x = 99;",         # x is reassigned, but this new value might not be used
    "dead_again = x;", # This assignment might be dead if 'dead_again' isn't used
    "print(a);",       # Uses 'a'
    "print(b);",       # Uses 'b'
    "print(c);"        # Uses 'c'
    # 'z' is used only in dead_var assignment (so z might be considered dead too in a deeper analysis)
    # 'x' is used in 'b = a - x', but the final assignment 'x=99' is dead.
    # 'y' is used.
]

print("--- Original Code ---")
for l in input_code_dead_const: print(l)

propagated_code, found_constants = constant_propagation(input_code_dead_const)
final_code = dead_code_elimination(propagated_code, found_constants)

print("\n--- Final Optimized Code ---")
for l in final_code:
    print(l.strip())
</code></pre>
                 </div>
            </div>
        </div>

        <!-- ==========================
             INTERMEDIATE CODE GENERATION
             ========================== -->
        <div class="code-container">
            <h2 class="text-2xl">7. Intermediate Code Generation (3-Address Code)</h2>

            <!-- Triples -->
            <div>
                <h3 class="text-xl">7a. Using Triples</h3>
                <p>Generates 3-Address Code in the form of Triples (Operator, Operand1, Operand2) for simple arithmetic expressions.</p>
                 <div class="run-command">
                    <strong>Language:</strong> Python<br>
                    <strong>Execution:</strong> <code>python icg_triples.py</code> (Save code as this file)
                </div>
                 <div class="code-block-container">
                    <button class="copy-btn" data-target-id="code-icg-7a">Copy</button>
                    <pre id="code-icg-7a"><code class="language-python">
# Global counter for triples
triple_index = 0
triples = [] # List to store the generated triples: {'index': i, 'op': o, 'arg1': a1, 'arg2': a2}
symbol_results = {} # Track which variable holds the result of which triple index

def generate_triple(op, arg1, arg2):
    """Adds a new triple to the list and returns its index reference."""
    global triple_index, triples
    # Check if args are references to previous triples (e.g., '(0)')
    # In a real parser, args would be variable names or temporary results (indices)
    arg1_ref = symbol_results.get(arg1, arg1) # Use index if var holds previous result
    arg2_ref = symbol_results.get(arg2, arg2)

    triples.append({'index': triple_index, 'op': op, 'arg1': arg1_ref, 'arg2': arg2_ref})
    current_index = triple_index
    triple_index += 1
    return f"({current_index})" # Return reference string '(index)'

def process_expression_triples(expr):
    """Processes a simple arithmetic expression and generates triples.
       Handles only single binary +,-,*,/ operations for simplicity.
       Assumes format like 'a + b' or 'a * (0)' where (0) is a triple ref.
       Returns the index reference string representing the final result.
    """
    # Very basic parsing - assumes simple 'arg1 op arg2' or just 'arg1'
    parts = expr.split()
    if len(parts) == 3:
        op = parts[1]
        arg1 = parts[0]
        arg2 = parts[2]
        if op in ['+', '-', '*', '/']:
            return generate_triple(op, arg1, arg2)
        else:
            print(f"Warning: Unsupported operator '{op}'")
            return expr # Return expression as is
    elif len(parts) == 1:
        # If it's already a reference or a variable/literal, return it
        return symbol_results.get(parts[0], parts[0])
    else:
         print(f"Warning: Cannot process complex expression '{expr}'")
         return expr # Return as is

# --- Example Usage ---
input_statements_triples = [
    "a = b + c",
    "d = a * e",
    "f = d + b", # Use d (result of (1)) and b
    "g = a + d"  # Use a (result of (0)) and d (result of (1))
]

print("--- Generating Triples ---")
print(f"{'Statement':<15} | {'Generated Triple Index'} | {'Variable Holds Result'}")
print("-" * 60)

# Reset global state for fresh run
triple_index = 0
triples = []
symbol_results = {}

for stmt in input_statements_triples:
    parts = stmt.split('=', 1)
    if len(parts) == 2:
        target_var = parts[0].strip()
        expression = parts[1].strip()

        result_ref = process_expression_triples(expression)
        symbol_results[target_var] = result_ref # Store reference for target var

        print(f"{stmt:<15} | {result_ref:<20} | {target_var} = {result_ref}")

    else:
         print(f"{stmt:<15} | Skipped (not simple assignment)")


print("\n--- Final Triples Table ---")
print(f"{'Index':<6}{'Operator':<10}{'Operand 1':<10}{'Operand 2':<10}")
print("-" * 40)
for t in triples:
    print(f"({t['index']:<4}){t['op']:<10}{t['arg1']:<10}{t['arg2']:<10}")

print("\n--- Variable Result Mapping ---")
for var, ref in symbol_results.items():
    print(f"{var} holds result of Triple {ref}")

</code></pre>
                 </div>
            </div>

            <!-- Quadruples -->
            <div>
                <h3 class="text-xl">7b. Using Quadruples</h3>
                <p>Generates 3-Address Code in the form of Quadruples (Operator, Operand1, Operand2, Result) for simple arithmetic expressions, using temporary variables.</p>
                 <div class="run-command">
                    <strong>Language:</strong> Python<br>
                    <strong>Execution:</strong> <code>python icg_quadruples.py</code> (Save code as this file)
                </div>
                 <div class="code-block-container">
                     <button class="copy-btn" data-target-id="code-icg-7b">Copy</button>
                    <pre id="code-icg-7b"><code class="language-python">
# Global counter for quadruples and temps
quad_index = 0
quadruples = [] # List to store generated quadruples: {'index': i, 'op': o, 'arg1': a1, 'arg2': a2, 'result': r}
temp_var_count = 0
symbol_table_temps = {} # Tracks which temp/var holds the current value of a variable/expression

def get_temp():
    """Generates a new temporary variable name."""
    global temp_var_count
    temp_var_count += 1
    return f"t{temp_var_count}"

def generate_quad(op, arg1, arg2, result):
    """Adds a new quadruple to the list."""
    global quad_index, quadruples
    # Resolve args using the symbol table if they map to temps
    arg1_resolved = symbol_table_temps.get(arg1, arg1)
    arg2_resolved = symbol_table_temps.get(arg2, arg2)

    quadruples.append({'index': quad_index, 'op': op, 'arg1': arg1_resolved, 'arg2': arg2_resolved, 'result': result})
    print(f"  Generated Quad ({quad_index}): ({op}, {arg1_resolved}, {arg2_resolved}, {result})") # Debug print
    quad_index += 1

def process_expression_quads(expr):
    """Processes a simple arithmetic expression (e.g., 'a + b')
       and generates quadruples. Returns the name of the variable/temp
       holding the result. Updates global symbol_table_temps.
    """
    global symbol_table_temps
    # Basic parsing for 'arg1 op arg2'
    parts = expr.split()
    if len(parts) == 3:
        op = parts[1]
        arg1 = parts[0]
        arg2 = parts[2]

        if op in ['+', '-', '*', '/']:
            result_temp = get_temp()
            generate_quad(op, arg1, arg2, result_temp)
            # The result of this expression is now stored in result_temp
            symbol_table_temps[expr] = result_temp # Can map expression itself? Or rely on assignment step.
            return result_temp # Return the temporary variable
        else:
             print(f"Warning: Unsupported operator '{op}' in expression '{expr}'")
             return expr # Cannot process
    elif len(parts) == 1:
        # Just a variable or literal, return its current location (might be a temp)
         return symbol_table_temps.get(parts[0], parts[0])
    else:
        print(f"Warning: Cannot process complex expression '{expr}'")
        return expr # Cannot process

# --- Example Usage ---
input_statements_quads = [
    "a = b + c",    # t1 = b + c; a = t1
    "d = a * e",    # t2 = a * e; d = t2
    "f = d + a",    # t3 = d + a; f = t3
    "g = b + c"     # t4 = b + c; g = t4 (No CSE here, simple ICG)
]

print("--- Generating Quadruples ---")
print(f"{'Statement':<15} | {'Generated Quad(s) Details'}")
print("-" * 60)

# Reset global state
quad_index = 0
quadruples = []
temp_var_count = 0
symbol_table_temps = {}

for stmt in input_statements_quads:
    parts = stmt.split('=', 1)
    if len(parts) == 2:
        target_var = parts[0].strip()
        expression = parts[1].strip()

        print(f"{stmt:<15} | Processing...")

        result_location = process_expression_quads(expression)

        # Generate the final assignment quadruple: target_var = result_location
        # unless the expression was just a single variable/temp already
        if result_location != target_var:
             generate_quad('=', result_location, '', target_var)

        # Update symbol table: target_var now holds the value represented by result_location
        # For simplicity, we often just map target_var to itself after assignment.
        symbol_table_temps[target_var] = target_var # After 'a = t1', 'a' holds the value.
        print(f"          -> {target_var} now holds result {symbol_table_temps[target_var]}")


    else:
         print(f"{stmt:<15} | Skipped (not simple assignment)")


print("\n--- Final Quadruples Table ---")
print(f"{'Index':<6}{'Operator':<10}{'Operand 1':<10}{'Operand 2':<10}{'Result':<10}")
print("-" * 50)
for q in quadruples:
    print(f"({q['index']:<4}){q['op']:<10}{q['arg1']:<10}{q['arg2']:<10}{q['result']:<10}")

</code></pre>
                 </div>
            </div>
        </div>

    </main>

    <footer class="text-center p-6 mt-8 text-gray-600 text-sm border-t border-gray-300">
        SPCC Practical Examples
    </footer>

    <script>
        document.addEventListener('DOMContentLoaded', (event) => {
            // Initialize Highlight.js
            hljs.highlightAll();

            // --- Copy Button Functionality ---
            const copyButtons = document.querySelectorAll('.copy-btn');

            copyButtons.forEach(button => {
                button.addEventListener('click', () => {
                    const targetId = button.dataset.targetId;
                    const targetElement = document.getElementById(targetId);

                    if (targetElement) {
                        const codeToCopy = targetElement.textContent; // Get text content

                        navigator.clipboard.writeText(codeToCopy).then(() => {
                            // Success feedback
                            button.textContent = 'Copied!';
                            button.classList.add('copied'); // Optional: for styling feedback
                            setTimeout(() => {
                                button.textContent = 'Copy';
                                button.classList.remove('copied');
                            }, 2000); // Reset after 2 seconds
                        }).catch(err => {
                            console.error('Failed to copy text: ', err);
                            button.textContent = 'Error';
                             setTimeout(() => {
                                button.textContent = 'Copy';
                            }, 2000);
                        });
                    } else {
                        console.error('Target element not found for ID:', targetId);
                        button.textContent = 'Error';
                    }
                });
            });
            // --- End Copy Button Functionality ---
        });
    </script>

</body>
</html>
